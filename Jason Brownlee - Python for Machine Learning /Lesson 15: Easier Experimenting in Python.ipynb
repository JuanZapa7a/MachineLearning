{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Lesson 15: Easier Experimenting in Python](https://machinelearningmastery.com/easier-experimenting-in-python/)\n",
    "\n",
    "When we work on a machine learning project, we quite often need to experiment\n",
    "with multiple alternatives. Some features in Python allow us to try out\n",
    "different options without much effort. In this tutorial, we are going to see\n",
    "some tips to make our experiments faster.\n",
    "\n",
    "After finishing this tutorial, you will learn:\n",
    "\n",
    "*  How to leverage a duck-typing feature to easily swap functions and objects\n",
    "*  How making components into drop-in replacements for  each other can help experiments run faster\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial is in three parts; they are:\n",
    "\n",
    "*    Workflow of a machine learning project\n",
    "*    Functions as objects\n",
    "*    Caveats\n",
    "\n",
    "## Workflow of a Machine Learning Project\n",
    "\n",
    "Consider a very simple machine learning project as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = read_csv(url, names=names)\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "\n",
    "# Train\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "score = clf.score(X_val, y_val)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a typical machine learning project workflow. We have a stage of\n",
    "preprocessing the data, then training a model, and afterward, evaluating our\n",
    "result. But in each step, we may want to try something different. For example,\n",
    "we may wonder if normalizing the data would make it better. So we may rewrite\n",
    "the code above into the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = read_csv(url, names=names)\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "\n",
    "# Train\n",
    "clf = Pipeline([('scaler',StandardScaler()), ('classifier',SVC())])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "score = clf.score(X_val, y_val)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. But what if we keep experimenting with different datasets,\n",
    "different models, or different score functions? Each time, we keep flipping\n",
    "between using a scaler and not would mean a lot of code change, and it would be\n",
    "quite easy to make mistakes.\n",
    "\n",
    "Because Python supports duck typing, we can see that the following two\n",
    "classifier models implemented the same interface:\n",
    "\n",
    "```python\n",
    "clf = SVC()\n",
    "clf = Pipeline([('scaler',StandardScaler()), ('classifier',SVC())])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can simply select between these two version and keep everything\n",
    "intact. We can say these two models are **drop-in replacements** for each other.\n",
    "\n",
    "Making use of this property, we can create a toggle variable to control the\n",
    "design choice we make:\n",
    "\n",
    "```python\n",
    "USE_SCALER = True\n",
    "\n",
    "if USE_SCALER:\n",
    "    clf = Pipeline([('scaler',StandardScaler()), ('classifier',SVC())])\n",
    "else:\n",
    "    clf = SVC()\n",
    "```\n",
    "\n",
    "By toggling the variable USE_SCALER between True and False, we can select\n",
    "whether a scaler should be applied. A more complex example would be to select\n",
    "among different scaler and the classifier models, such as:\n",
    "\n",
    "```python\n",
    "SCALER = \"standard\"\n",
    "CLASSIFIER = \"svc\"\n",
    "\n",
    "if CLASSIFIER == \"svc\":\n",
    "    model = SVC()\n",
    "elif CLASSIFIER == \"cart\":\n",
    "    model = DecisionTreeClassifier()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if SCALER == \"standard\":\n",
    "    clf = Pipeline([('scaler',StandardScaler()), ('classifier',model)])\n",
    "elif SCALER == \"maxmin\":\n",
    "    clf = Pipeline([('scaler',MaxMinScaler()), ('classifier',model)])\n",
    "elif SCALER == None:\n",
    "    clf = model\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "```\n",
    "\n",
    "A complete example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# toggle between options\n",
    "SCALER = \"maxmin\"    # \"standard\", \"maxmin\", or None\n",
    "CLASSIFIER = \"cart\"  # \"svc\" or \"cart\"\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = read_csv(url, names=names)\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "\n",
    "# Create model\n",
    "if CLASSIFIER == \"svc\":\n",
    "    model = SVC()\n",
    "elif CLASSIFIER == \"cart\":\n",
    "    model = DecisionTreeClassifier()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if SCALER == \"standard\":\n",
    "    clf = Pipeline([('scaler',StandardScaler()), ('classifier',model)])\n",
    "elif SCALER == \"maxmin\":\n",
    "    clf = Pipeline([('scaler',MinMaxScaler()), ('classifier',model)])\n",
    "elif SCALER == None:\n",
    "    clf = model\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "score = clf.score(X_val, y_val)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you go one step further, you may even skip the toggle variable and use a\n",
    "string directly for a quick experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Covariance matrix and Cholesky decomposition\n",
    "cov = np.array([[1, 0.8], [0.8, 1]])\n",
    "L = np.linalg.cholesky(cov)\n",
    "\n",
    "# Generate 100 pairs of bi-variate Gaussian random numbers\n",
    "if not \"USE SCIPY\":\n",
    "   z = np.random.randn(100,2)\n",
    "   x = z @ L.T\n",
    "else:\n",
    "   x = stats.multivariate_normal(mean=[0, 0], cov=cov).rvs(100)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions as Objects\n",
    "\n",
    "In Python, functions are first-class citizens. You can assign functions to a\n",
    "variable. Indeed, functions are objects in Python, as are classes (the classes\n",
    "themselves, not only incarnations of classes). Therefore, we can use the same\n",
    "technique as above to experiment with similar functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86619299 -0.77271035 -0.34083775  0.94584046  1.20764607]\n",
      " [ 2.58773325  1.87003246 -0.06062041 -1.35006146 -0.18093381]\n",
      " [ 0.25698579  0.97225107  1.10114656 -0.08460816  0.98743163]\n",
      " [-1.15273051 -1.33611763 -0.295313    0.26662775  0.61416427]\n",
      " [-0.42849996 -0.29843637  0.48836518  0.97169038  0.80842449]\n",
      " [ 1.72818914 -1.02712406 -0.88652396  0.80512848  2.22228372]\n",
      " [-0.28981209  0.8426274   1.06113198 -0.17351963 -1.04606195]\n",
      " [ 0.61776735  0.03378074 -1.07895001  0.82524569 -0.69548583]\n",
      " [-0.58358819  1.50284277 -1.7930183  -0.89507719  1.56105326]\n",
      " [ 0.35353722  1.61784557 -0.28944177 -0.69882227  0.39400301]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "DIST = \"normal\"\n",
    "\n",
    "if DIST == \"normal\":\n",
    "    rangen = np.random.normal\n",
    "elif DIST == \"uniform\":\n",
    "    rangen = np.random.uniform\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "random_data = rangen(size=(10,5))\n",
    "print(random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is similar to calling `np.random.normal(size=(10,5))`, but we hold the\n",
    "function in a variable for the convenience of swapping one function with\n",
    "another. Note that since we call the functions with the same argument, we have\n",
    "to make sure all variations will accept it. In case it is not, we may need some\n",
    "additional lines of code to make a wrapper. For example, in the case of\n",
    "generating Student’s t distribution, we need an additional parameter for the\n",
    "degree of freedom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.19396605e-01  3.38445042e-01 -1.55661615e+00 -1.18975355e+01\n",
      "   3.32717421e-02]\n",
      " [-1.38300917e+00  3.39365346e-02  1.16849881e-01 -5.05266443e-01\n",
      "   3.81296725e-03]\n",
      " [-5.04704399e-01 -3.78061996e+00  1.15895686e-01  8.81443056e-01\n",
      "   1.38002427e+00]\n",
      " [-2.44610708e+00 -1.30681111e+00 -2.21450226e+00 -1.21229398e+00\n",
      "   1.49474875e-01]\n",
      " [ 3.60770537e-01 -2.25237759e-01  3.01802173e+00 -1.01772683e+00\n",
      "   8.48512583e+00]\n",
      " [ 8.44193526e-01  5.41234948e-01 -1.10938159e-01 -4.20624675e+00\n",
      "  -7.85112961e-01]\n",
      " [ 7.15638095e-01 -1.81740908e+00 -6.75764943e-01 -1.42905855e+00\n",
      "   3.99267812e-01]\n",
      " [-1.81070355e+00 -3.57456675e-01  2.69219360e+00 -9.40644657e-01\n",
      "  -5.53745257e-01]\n",
      " [ 2.04680196e+00  5.62444894e-01 -1.36432432e+00 -1.35008782e+00\n",
      "  -1.03299582e+00]\n",
      " [ 4.77883311e-02  5.00605340e+00  5.11059348e-01 -1.02327832e+00\n",
      "  -1.14930244e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "DIST = \"t\"\n",
    "\n",
    "if DIST == \"normal\":\n",
    "    rangen = np.random.normal\n",
    "elif DIST == \"uniform\":\n",
    "    rangen = np.random.uniform\n",
    "elif DIST == \"t\":\n",
    "    def t_wrapper(size):\n",
    "        # Student's t distribution with 3 degree of freedom\n",
    "        return np.random.standard_t(df=3, size=size)\n",
    "    rangen = t_wrapper\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "random_data = rangen(size=(10,5))\n",
    "print(random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works because in the above, `np.random.normal`, `np.random.uniform`, and\n",
    "`t_wrapper` as we defined, are all drop-in replacements of each other.\n",
    "\n",
    "## Caveats\n",
    "\n",
    "Machine learning differs from other programming projects because there are more\n",
    "uncertainties in the workflow. When you build a web page or build a game, you\n",
    "have a picture in your mind of what to achieve. But there is some exploratory\n",
    "work in machine learning projects.\n",
    "\n",
    "You will probably use some source code control system like git or Mercurial to\n",
    "manage your source code development history in other projects. In machine\n",
    "learning projects, however, we are trying out different combinations of many\n",
    "steps. Using git to manage the different variations may not fit, not to say\n",
    "sometimes may be overkill. Therefore, using a toggle variable to control the\n",
    "flow should allow us to try out different things faster. This is especially\n",
    "handy when we are working on our projects in Jupyter notebooks.\n",
    "\n",
    "However, as we put multiple versions of code together, we made the program\n",
    "clumsy and less readable. It is better to do some clean-up after we confirm what\n",
    "to do. This will help us with maintenance in the future.\n",
    "\n",
    "## Further reading\n",
    "\n",
    "This section provides more resources on the topic if you are looking to go deeper.\n",
    "\n",
    "### Books\n",
    "\n",
    "* Fluent Python, second edition, by Luciano Ramalho, https://www.amazon.com/dp/1492056359/\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this tutorial, you’ve seen how the duck typing property in Python helps us create drop-in replacements. Specifically, you learned:\n",
    "\n",
    "*    Duck typing can help us switch between alternatives easily in a machine learning workflow\n",
    "*    We can make use of a toggle variable to experiment among alternatives\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dl4cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd20b80f3abe9c1782c169f75cb3aaf4fed19688fa30b13c4021414b02823d14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
